import Foundation
import Combine

final class CaptureController: ObservableObject {
    private var cancellables = Set<AnyCancellable>()
    private var audioEngine: AudioEngine?

    func start(appState: AppState) {
        appState.log("ğŸš€ Start requested")

        // 1) Ä°zin kontrolÃ¼
        guard appState.isMicAuthorized else {
            appState.log("âŒ BaÅŸlatÄ±lamadÄ±: Mikrofon izni yok.")
            return
        }

        // 2) API Key kontrolÃ¼
        if !APIKeyManager.hasValidAPIKey() {
            appState.log("âŒ BaÅŸlatÄ±lamadÄ±: DEEPGRAM_API_KEY eksik.")
            return
        }

        // 3) AudioEngine oluÅŸtur
        let config = makeDGConfig()
        audioEngine = AudioEngine(config: config)
        
        // 4) Event handler'Ä± ayarla
        audioEngine?.onEvent = { [weak self] event in
            self?.handleAudioEngineEvent(event, appState: appState)
        }

        // 5) BaÅŸlat
        audioEngine?.start()
        appState.isCapturing = true
        appState.log("âœ… Capture started.")
    }

    func stop(appState: AppState) {
        appState.log("ğŸ›‘ Stop requested")
        audioEngine?.stop()
        appState.isCapturing = false
        appState.log("âœ… Capture stopped.")
    }

    // MARK: - AudioEngine Event Handling
    private func handleAudioEngineEvent(_ event: AudioEngineEvent, appState: AppState) {
        DispatchQueue.main.async {
            switch event {
            case .microphoneConnected:
                appState.log("ğŸ¤ Mikrofon Deepgram'e baÄŸlandÄ±.")
            case .systemAudioConnected:
                appState.log("ğŸ”Š Sistem sesi Deepgram'e baÄŸlandÄ±.")
            case .microphoneDisconnected:
                appState.log("ğŸ¤ Mikrofon Deepgram baÄŸlantÄ±sÄ± kesildi.")
            case .systemAudioDisconnected:
                appState.log("ğŸ”Š Sistem sesi Deepgram baÄŸlantÄ±sÄ± kesildi.")
            case .error(let error, let source):
                appState.log("âŒ \(source.debugId) HatasÄ±: \(error.localizedDescription)")
            case .results(let json, let source):
                self.parseDeepgramResults(json, source: source, appState: appState)
            case .metadata(let json, let source):
                appState.log("â„¹ï¸ \(source.debugId) Metadata: \(json.prefix(100))...")
            case .finalized(let json, let source):
                appState.log("âœ… \(source.debugId) Finalize: \(json.prefix(100))...")
                self.parseDeepgramResults(json, source: source, appState: appState, isFinal: true)
            }
        }
    }

    private func parseDeepgramResults(_ jsonString: String, source: AudioSourceType, appState: AppState, isFinal: Bool = false) {
        do {
            guard let jsonData = jsonString.data(using: .utf8) else {
                appState.log("âŒ JSON data conversion failed.")
                return
            }
            let json = try JSONSerialization.jsonObject(with: jsonData, options: []) as? [String: Any]

            guard let results = json?["channel"] as? [String: Any],
                  let alternatives = results["alternatives"] as? [[String: Any]],
                  let firstAlternative = alternatives.first,
                  let transcript = firstAlternative["transcript"] as? String,
                  !transcript.isEmpty else {
                return
            }

            let speaker = (source == .microphone) ? "You" : "Them"
            appState.log("ğŸ“ \(isFinal ? "Final" : "Partial") (\(source.debugId)): \(transcript)")

            // Add to transcript items if final
            if isFinal {
                let transcriptItem = TranscriptItem(
                    speaker: speaker,
                    text: transcript,
                    translation: nil,
                    isYou: source == .microphone
                )
                appState.addTranscript(transcriptItem)
            }
        } catch {
            appState.log("âŒ JSON parse error: \(error.localizedDescription)")
        }
    }
}
